pip install pyspark
pip install mysql-connector-python

CREATE TABLE neic_earthquakes (
    Date DATE,
    Time TIME,
    Latitude FLOAT,
    Longitude FLOAT,
    Type VARCHAR(50),
    Depth FLOAT,
    Depth_Error FLOAT,
    Depth_Seismic_Stations INT,
    Magnitude FLOAT,
    Magnitude_Type VARCHAR(10),
    Magnitude_Error FLOAT,
    Magnitude_Seismic_Stations INT,
    Azimuthal_Gap FLOAT,
    Horizontal_Distance FLOAT,
    Horizontal_Error FLOAT,
    Root_Mean_Square FLOAT,
    ID VARCHAR(20),
    Source VARCHAR(20),
    Location_Source VARCHAR(20),
    Magnitude_Source VARCHAR(20),
    Status VARCHAR(20)
);

import pandas as pd
import mysql.connector
from pyspark.sql import SparkSession

# Load data into Pandas DataFrame
data = pd.read_csv('path/to/your/dataset.csv')

# Connect to MySQL and create neic_earthquakes table
conn = mysql.connector.connect(host='localhost', user='your_user', password='your_password', database='your_db')
cursor = conn.cursor()

# Insert data into MySQL
for index, row in data.iterrows():
    cursor.execute(f"""
        INSERT INTO neic_earthquakes VALUES (
            '{row['Date']}', '{row['Time']}', {row['Latitude']}, {row['Longitude']}, 
            '{row['Type']}', {row['Depth']}, {row['Depth Error']}, {row['Depth Seismic Stations']}, 
            {row['Magnitude']}, '{row['Magnitude Type']}', {row['Magnitude Error']}, 
            {row['Magnitude Seismic Stations']}, {row['Azimuthal Gap']}, {row['Horizontal Distance']}, 
            {row['Horizontal Error']}, {row['Root Mean Square']}, '{row['ID']}', 
            '{row['Source']}', '{row['Location Source']}', '{row['Magnitude Source']}', 
            '{row['Status']}'
        )
    """)

conn.commit()
cursor.close()
conn.close()

from pyspark.sql import SparkSession
from pyspark.sql.functions import dayofweek, month, year, col

# Create a Spark session
spark = SparkSession.builder.appName("EarthquakeAnalysis").getOrCreate()

# Read data from MySQL into PySpark DataFrame
df = spark.read.format("jdbc").option("url", "jdbc:mysql://localhost:3306/your_db").option("dbtable", "neic_earthquakes").option("user", "your_user").option("password", "your_password").load()

# Answer the questions using PySpark functions
# Example: How does the Day of a Week affect the number of earthquakes?
df.withColumn("DayOfWeek", dayofweek("Date")).groupBy("DayOfWeek").count().show()

# What is the relation between Day of the month and Number of earthquakes that happened in a year?
day_month_relation = df.groupBy(year("Date").alias("Year"), month("Date").alias("Month"), dayofmonth("Date").alias("DayOfMonth")).count()

# What does the average frequency of earthquakes in a month from the year 1965 to 2016 tell us?
avg_frequency_by_month = df.filter((year("Date") >= 1965) & (year("Date") <= 2016)).groupBy(month("Date").alias("Month")).agg(avg("Magnitude").alias("Average_Magnitude"), count("ID").alias("Number_of_Earthquakes"))

# What is the relation between Year and Number of earthquakes that happened in that year?
year_relation = df.groupBy(year("Date").alias("Year")).count()

# How has the earthquake magnitude on average been varied over the years?
magnitude_variation = df.groupBy(year("Date").alias("Year")).agg(avg("Magnitude").alias("Average_Magnitude"))

# How does year impact the standard deviation of the earthquakes?
magnitude_std_deviation = df.groupBy(year("Date").alias("Year")).agg(stddev("Magnitude").alias("Magnitude_StdDev"))

# Does geographic location have anything to do with earthquakes?
location_analysis = df.groupBy("Location_Source").agg(count("ID").alias("Number_of_Earthquakes")).orderBy(col("Number_of_Earthquakes").desc())

# Where do earthquakes occur very frequently?
frequent_locations = location_analysis.filter(col("Number_of_Earthquakes") > 100)

# What is the relation between Magnitude, Magnitude Type, Status and Root Mean Square of the earthquakes?
magnitude_relation = df.groupBy("Magnitude", "Magnitude_Type", "Status", "Root_Mean_Square").count()

# Show results
day_month_relation.show()
avg_frequency_by_month.show()
year_relation.show()
magnitude_variation.show()
magnitude_std_deviation.show()
location_analysis.show()
frequent_locations.show()
magnitude_relation.show()

